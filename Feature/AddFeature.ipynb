{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= list(range(10))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6a1284577a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a[0]a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123333 not buy size befor duplicate\n"
     ]
    }
   ],
   "source": [
    "label_day = \"123333\"\n",
    "print(label_day,\"not buy size befor duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002961767229830952"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rule1\n",
    "P = 0.03768433\n",
    "F = 0.0005877342\n",
    "R = F*P/(2*P-F)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003446036591175452"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rule2\n",
    "P = 0.05189621\n",
    "F = 0.0006846610\n",
    "R = F*P/(2*P-F)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00034915661540274535"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rule3\n",
    "P = 0.04705882\n",
    "F = 0.0006931702\n",
    "R = F*P/(2*P-F)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_testset(train_user,LabelDay):\n",
    "    # 测试集选为上一天所有的交互数据\n",
    "    data_test = train_user[(train_user['daystime'] == LabelDay)]#&((train_user.behavior_type==3)|(train_user.behavior_type==2))\n",
    "    data_test = data_test.drop_duplicates(['user_id', 'item_id'])\n",
    "    return data_test[['user_id', 'item_id','item_category']]\n",
    "\n",
    "\n",
    "\n",
    "def item_category_feture(data,end_time,beforeoneday):\n",
    "    # data = Data[(Data['daystime']<LabelDay) & (Data['daystime']>LabelDay-datetime.timedelta(days=FEATURE_EXTRACTION_SLOT))]\n",
    "    item_count = pd.crosstab(data.item_category,data.behavior_type)\n",
    "    item_count_before5=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforefiveday = data[data['daystime']>=end_time-datetime.timedelta(days=5+2)]\n",
    "        item_count_before5 = pd.crosstab(beforefiveday.item_category,beforefiveday.behavior_type)\n",
    "    else:\n",
    "        beforefiveday = data[data['daystime']>=end_time-datetime.timedelta(days=5)]\n",
    "        item_count_before5 = pd.crosstab(beforefiveday.item_category,beforefiveday.behavior_type)\n",
    "    item_count_before_3=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=3+2)]\n",
    "        item_count_before_3 = pd.crosstab(beforethreeday.item_category,beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=3)]\n",
    "        item_count_before_3 = pd.crosstab(beforethreeday.item_category,beforethreeday.behavior_type)\n",
    "\n",
    "    item_count_before_2=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=7+2)]\n",
    "        item_count_before_2 = pd.crosstab(beforethreeday.item_category,beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=7)]\n",
    "        item_count_before_2 = pd.crosstab(beforethreeday.item_category,beforethreeday.behavior_type)\n",
    "        \n",
    "    # beforeoneday = Data[Data['daystime'] == LabelDay-datetime.timedelta(days=1)]\n",
    "    beforeonedayitem_count = pd.crosstab(beforeoneday.item_category,beforeoneday.behavior_type)\n",
    "    countAverage = item_count/FEATURE_EXTRACTION_SLOT\n",
    "    buyRate = pd.DataFrame()\n",
    "    buyRate['click'] = item_count[1]/item_count[4]\n",
    "    buyRate['skim'] = item_count[2]/item_count[4]\n",
    "    buyRate['collect'] = item_count[3]/item_count[4]\n",
    "    buyRate.index = item_count.index\n",
    "\n",
    "    buyRate_2 = pd.DataFrame()\n",
    "    buyRate_2['click'] = item_count_before5[1]/item_count_before5[4]\n",
    "    buyRate_2['skim'] = item_count_before5[2]/item_count_before5[4]\n",
    "    buyRate_2['collect'] = item_count_before5[3]/item_count_before5[4]\n",
    "    buyRate_2.index = item_count_before5.index\n",
    "\n",
    "    buyRate_3 = pd.DataFrame()\n",
    "    buyRate_3['click'] = item_count_before_3[1]/item_count_before_3[4]\n",
    "    buyRate_3['skim'] = item_count_before_3[2]/item_count_before_3[4]\n",
    "    buyRate_3['collect'] = item_count_before_3[3]/item_count_before_3[4]\n",
    "    buyRate_3.index = item_count_before_3.index\n",
    "\n",
    "\n",
    "    buyRate = buyRate.replace([np.inf, -np.inf], 0)\n",
    "    buyRate_2 = buyRate_2.replace([np.inf, -np.inf], 0)\n",
    "    buyRate_3 = buyRate_3.replace([np.inf, -np.inf], 0)\n",
    "    item_category_feture = pd.merge(item_count,beforeonedayitem_count,how='left',right_index=True,left_index=True)\n",
    "    item_category_feture = pd.merge(item_category_feture,countAverage,how='left',right_index=True,left_index=True)\n",
    "    item_category_feture = pd.merge(item_category_feture,buyRate,how='left',right_index=True,left_index=True)\n",
    "    item_category_feture = pd.merge(item_category_feture,item_count_before5,how='left',right_index=True,left_index=True)\n",
    "    item_category_feture = pd.merge(item_category_feture,item_count_before_3,how='left',right_index=True,left_index=True)\n",
    "    item_category_feture = pd.merge(item_category_feture,item_count_before_2,how='left',right_index=True,left_index=True)\n",
    "#    item_category_feture = pd.merge(item_category_feture,buyRate_2,how='left',right_index=True,left_index=True)\n",
    "#    item_category_feture = pd.merge(item_category_feture,buyRate_3,how='left',right_index=True,left_index=True)\n",
    "    item_category_feture.fillna(0,inplace=True)\n",
    "    return item_category_feture\n",
    "\n",
    "def item_id_feture(data,end_time,beforeoneday):   \n",
    "    # data = Data[(Data['daystime']<LabelDay) & (Data['daystime']>LabelDay-datetime.timedelta(days=FEATURE_EXTRACTION_SLOT))]\n",
    "    item_count = pd.crosstab(data.item_id,data.behavior_type)\n",
    "    item_count_before5=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforefiveday = data[data['daystime']>=end_time-datetime.timedelta(days=5+2)]\n",
    "        item_count_before5 = pd.crosstab(beforefiveday.item_id,beforefiveday.behavior_type)\n",
    "    else:\n",
    "        beforefiveday = data[data['daystime']>=end_time-datetime.timedelta(days=5)]\n",
    "        item_count_before5 = pd.crosstab(beforefiveday.item_id,beforefiveday.behavior_type)\n",
    "\n",
    "    item_count_before_3=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=3+2)]\n",
    "        item_count_before_3 = pd.crosstab(beforethreeday.item_id,beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=3)]\n",
    "        item_count_before_3 = pd.crosstab(beforethreeday.item_id,beforethreeday.behavior_type)\n",
    "\n",
    "    item_count_before_2=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=7+2)]\n",
    "        item_count_before_2 = pd.crosstab(beforethreeday.item_id,beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=7)]\n",
    "        item_count_before_2 = pd.crosstab(beforethreeday.item_id,beforethreeday.behavior_type)\n",
    "        \n",
    "    item_count_unq = data.groupby(by = ['item_id','behavior_type']).agg({\"user_id\":lambda x:x.nunique()});item_count_unq = item_count_unq.unstack()\n",
    "    # beforeoneday = Data[Data['daystime'] == LabelDay-datetime.timedelta(days=1)]\n",
    "    beforeonedayitem_count = pd.crosstab(beforeoneday.item_id,beforeoneday.behavior_type)\n",
    "    countAverage = item_count/FEATURE_EXTRACTION_SLOT\n",
    "    buyRate = pd.DataFrame()\n",
    "    buyRate['click'] = item_count[1]/item_count[4]\n",
    "    buyRate['skim'] = item_count[2]/item_count[4]\n",
    "    buyRate['collect'] = item_count[3]/item_count[4]\n",
    "    buyRate.index = item_count.index\n",
    "\n",
    "    buyRate_2 = pd.DataFrame()\n",
    "    buyRate_2['click'] = item_count_before5[1]/item_count_before5[4]\n",
    "    buyRate_2['skim'] = item_count_before5[2]/item_count_before5[4]\n",
    "    buyRate_2['collect'] = item_count_before5[3]/item_count_before5[4]\n",
    "    buyRate_2.index = item_count_before5.index\n",
    "\n",
    "    buyRate_3 = pd.DataFrame()\n",
    "    buyRate_3['click'] = item_count_before_3[1]/item_count_before_3[4]\n",
    "    buyRate_3['skim'] = item_count_before_3[2]/item_count_before_3[4]\n",
    "    buyRate_3['collect'] = item_count_before_3[3]/item_count_before_3[4]\n",
    "    buyRate_3.index = item_count_before_3.index\n",
    "\n",
    "    buyRate = buyRate.replace([np.inf, -np.inf], 0)\n",
    "    buyRate_2 = buyRate_2.replace([np.inf, -np.inf], 0)\n",
    "    buyRate_3 = buyRate_3.replace([np.inf, -np.inf], 0)\n",
    "    item_id_feture = pd.merge(item_count,beforeonedayitem_count,how='left',right_index=True,left_index=True)\n",
    "    item_id_feture = pd.merge(item_id_feture,countAverage,how='left',right_index=True,left_index=True)\n",
    "    item_id_feture = pd.merge(item_id_feture,buyRate,how='left',right_index=True,left_index=True)\n",
    "    item_id_feture = pd.merge(item_id_feture,item_count_unq,how='left',right_index=True,left_index=True)\n",
    "    item_id_feture = pd.merge(item_id_feture,item_count_before5,how='left',right_index=True,left_index=True)\n",
    "    item_id_feture = pd.merge(item_id_feture,item_count_before_3,how='left',right_index=True,left_index=True)\n",
    "    item_id_feture = pd.merge(item_id_feture,item_count_before_2,how='left',right_index=True,left_index=True)\n",
    "#    item_id_feture = pd.merge(item_id_feture,buyRate_2,how='left',right_index=True,left_index=True)\n",
    "#    item_id_feture = pd.merge(item_id_feture,buyRate_3,how='left',right_index=True,left_index=True)\n",
    "    item_id_feture.fillna(0,inplace=True)\n",
    "    return item_id_feture\n",
    "\n",
    "\n",
    "def user_id_feture(data,end_time,beforeoneday):   \n",
    "    # data = Data[(Data['daystime']<LabelDay) & (Data['daystime']>LabelDay-datetime.timedelta(days=FEATURE_EXTRACTION_SLOT))]\n",
    "    user_count = pd.crosstab(data.user_id,data.behavior_type)\n",
    "    user_count_before5=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforefiveday = data[data['daystime']>=end_time-datetime.timedelta(days=5+2)]\n",
    "        user_count_before5 = pd.crosstab(beforefiveday.user_id,beforefiveday.behavior_type)\n",
    "    else:\n",
    "        beforefiveday = data[data['daystime']>=end_time-datetime.timedelta(days=5)]\n",
    "        user_count_before5 = pd.crosstab(beforefiveday.user_id,beforefiveday.behavior_type)\n",
    "\n",
    "    user_count_before_3=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=3+2)]\n",
    "        user_count_before_3 = pd.crosstab(beforethreeday.user_id,beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=3)]\n",
    "        user_count_before_3 = pd.crosstab(beforethreeday.user_id,beforethreeday.behavior_type)\n",
    "\n",
    "    user_count_before_2=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=7+2)]\n",
    "        user_count_before_2 = pd.crosstab(beforethreeday.user_id,beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=7)]\n",
    "        user_count_before_2 = pd.crosstab(beforethreeday.user_id,beforethreeday.behavior_type)\n",
    "        \n",
    "    # beforeoneday = Data[Data['daystime'] == LabelDay-datetime.timedelta(days=1)]\n",
    "    beforeonedayuser_count = pd.crosstab(beforeoneday.user_id,beforeoneday.behavior_type)\n",
    "    countAverage = user_count/FEATURE_EXTRACTION_SLOT\n",
    "    buyRate = pd.DataFrame()\n",
    "    buyRate['click'] = user_count[1]/user_count[4]\n",
    "    buyRate['skim'] = user_count[2]/user_count[4]\n",
    "    buyRate['collect'] = user_count[3]/user_count[4]\n",
    "    buyRate.index = user_count.index\n",
    "\n",
    "    buyRate_2 = pd.DataFrame()\n",
    "    buyRate_2['click'] = user_count_before5[1]/user_count_before5[4]\n",
    "    buyRate_2['skim'] = user_count_before5[2]/user_count_before5[4]\n",
    "    buyRate_2['collect'] = user_count_before5[3]/user_count_before5[4]\n",
    "    buyRate_2.index = user_count_before5.index\n",
    "\n",
    "    buyRate_3 = pd.DataFrame()\n",
    "    buyRate_3['click'] = user_count_before_3[1]/user_count_before_3[4]\n",
    "    buyRate_3['skim'] = user_count_before_3[2]/user_count_before_3[4]\n",
    "    buyRate_3['collect'] = user_count_before_3[3]/user_count_before_3[4]\n",
    "    buyRate_3.index = user_count_before_3.index\n",
    "\n",
    "\n",
    "    buyRate = buyRate.replace([np.inf, -np.inf], 0)\n",
    "    buyRate_2 = buyRate_2.replace([np.inf, -np.inf], 0)\n",
    "    buyRate_3 = buyRate_3.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    long_online = pd.pivot_table(beforeoneday,index=['user_id'],values=['hours'],aggfunc=[np.min,np.max,np.ptp])\n",
    "\n",
    "\n",
    "    user_id_feture = pd.merge(user_count,beforeonedayuser_count,how='left',right_index=True,left_index=True)\n",
    "    user_id_feture = pd.merge(user_id_feture,countAverage,how='left',right_index=True,left_index=True)\n",
    "    user_id_feture = pd.merge(user_id_feture,buyRate,how='left',right_index=True,left_index=True)\n",
    "    user_id_feture = pd.merge(user_id_feture,user_count_before5,how='left',right_index=True,left_index=True)\n",
    "    user_id_feture = pd.merge(user_id_feture,user_count_before_3,how='left',right_index=True,left_index=True)\n",
    "    user_id_feture = pd.merge(user_id_feture,user_count_before_2,how='left',right_index=True,left_index=True)\n",
    "    user_id_feture = pd.merge(user_id_feture,long_online,how='left',right_index=True,left_index=True)\n",
    "#    user_id_feture = pd.merge(user_id_feture,buyRate_2,how='left',right_index=True,left_index=True)\n",
    "#    user_id_feture = pd.merge(user_id_feture,buyRate_3,how='left',right_index=True,left_index=True)\n",
    "    user_id_feture.fillna(0,inplace=True)\n",
    "    return user_id_feture\n",
    "\n",
    "\n",
    "\n",
    "def user_item_feture(data,end_time,beforeoneday):   \n",
    "    # data = Data[(Data['daystime']<LabelDay) & (Data['daystime']>LabelDay-datetime.timedelta(days=FEATURE_EXTRACTION_SLOT))]\n",
    "    user_item_count = pd.crosstab([data.user_id,data.item_id],data.behavior_type)\n",
    "    # beforeoneday = Data[Data['daystime'] == LabelDay-datetime.timedelta(days=1)]\n",
    "    user_item_count_5=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforefiveday = data[data['daystime']>=end_time-datetime.timedelta(days=5+2)]\n",
    "        user_item_count_5 = pd.crosstab([beforefiveday.user_id,beforefiveday.item_id],beforefiveday.behavior_type)\n",
    "    else:\n",
    "        beforefiveday = data[data['daystime']>=end_time-datetime.timedelta(days=5)]\n",
    "        user_item_count_5 = pd.crosstab([beforefiveday.user_id,beforefiveday.item_id],beforefiveday.behavior_type)\n",
    "    user_item_count_3=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=3+2)]\n",
    "        user_item_count_3 = pd.crosstab([beforethreeday.user_id,beforethreeday.item_id],beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=3)]\n",
    "        user_item_count_3 = pd.crosstab([beforethreeday.user_id,beforethreeday.item_id],beforethreeday.behavior_type)\n",
    "\n",
    "    user_item_count_2=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=7+2)]\n",
    "        user_item_count_2 = pd.crosstab([beforethreeday.user_id,beforethreeday.item_id],beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=end_time-datetime.timedelta(days=7)]\n",
    "        user_item_count_2 = pd.crosstab([beforethreeday.user_id,beforethreeday.item_id],beforethreeday.behavior_type)\n",
    "        \n",
    "    beforeonedayuser_item_count = pd.crosstab([beforeoneday.user_id,beforeoneday.item_id],beforeoneday.behavior_type)\n",
    "    \n",
    "#    _live = user_item_long_touch(data)\n",
    "    \n",
    "    \n",
    "    max_touchtime = pd.pivot_table(beforeoneday,index=['user_id','item_id'],values=['hours'],aggfunc=[np.min,np.max])\n",
    "    max_touchtype = pd.pivot_table(beforeoneday,index=['user_id','item_id'],values=['behavior_type'],aggfunc=np.max)\n",
    "    user_item_feture = pd.merge(user_item_count,beforeonedayuser_item_count,how='left',right_index=True,left_index=True)\n",
    "    user_item_feture = pd.merge(user_item_feture,max_touchtime,how='left',right_index=True,left_index=True)\n",
    "    user_item_feture = pd.merge(user_item_feture,max_touchtype,how='left',right_index=True,left_index=True)\n",
    "#    user_item_feture = pd.merge(user_item_feture,_live,how='left',right_index=True,left_index=True)\n",
    "\n",
    "    user_item_feture = pd.merge(user_item_feture,user_item_count_5,how='left',right_index=True,left_index=True)\n",
    "    user_item_feture = pd.merge(user_item_feture,user_item_count_3,how='left',right_index=True,left_index=True)\n",
    "    user_item_feture = pd.merge(user_item_feture,user_item_count_2,how='left',right_index=True,left_index=True)\n",
    "    user_item_feture.fillna(0,inplace=True)\n",
    "    return user_item_feture\n",
    "\n",
    "def user_cate_feture(data,end_time,beforeoneday):   \n",
    "    # data = Data[(Data['daystime']<LabelDay) & (Data['daystime']>LabelDay-datetime.timedelta(days=FEATURE_EXTRACTION_SLOT))]\n",
    "    user_item_count = pd.crosstab([data.user_id,data.item_category],data.behavior_type)\n",
    "    # beforeoneday = Data[Data['daystime'] == LabelDay-datetime.timedelta(days=1)]\n",
    "    \n",
    "    user_cate_count_5=None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforefiveday = data[data['daystime']>=(end_time-datetime.timedelta(days=5+2))]\n",
    "        user_cate_count_5 = pd.crosstab([beforefiveday.user_id,beforefiveday.item_category],beforefiveday.behavior_type)\n",
    "    else:\n",
    "        beforefiveday = data[data['daystime']>=(end_time-datetime.timedelta(days=5))]\n",
    "        user_cate_count_5 = pd.crosstab([beforefiveday.user_id,beforefiveday.item_category],beforefiveday.behavior_type)\n",
    "    user_cate_count_3 = None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=(end_time-datetime.timedelta(days=3+2))]\n",
    "        user_cate_count_3 = pd.crosstab([beforethreeday.user_id,beforethreeday.item_category],beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=(end_time-datetime.timedelta(days=3))]\n",
    "        user_cate_count_3 = pd.crosstab([beforethreeday.user_id,beforethreeday.item_category],beforethreeday.behavior_type)\n",
    "\n",
    "\n",
    "    user_cate_count_2 = None\n",
    "    if (((end_time-datetime.timedelta(days=5))<datetime.datetime(2014,12,13,0,0,0))&((end_time-datetime.timedelta(days=5))>datetime.datetime(2014,12,10,0,0,0))):\n",
    "        beforethreeday = data[data['daystime']>=(end_time-datetime.timedelta(days=7+2))]\n",
    "        user_cate_count_2 = pd.crosstab([beforethreeday.user_id,beforethreeday.item_category],beforethreeday.behavior_type)\n",
    "    else:\n",
    "        beforethreeday = data[data['daystime']>=(end_time-datetime.timedelta(days=7))]\n",
    "        user_cate_count_2 = pd.crosstab([beforethreeday.user_id,beforethreeday.item_category],beforethreeday.behavior_type)\n",
    "        \n",
    "#    _live = user_cate_long_touch(data)\n",
    "    beforeonedayuser_item_count = pd.crosstab([beforeoneday.user_id,beforeoneday.item_category],beforeoneday.behavior_type)\n",
    "    max_touchtime = pd.pivot_table(beforeoneday,index=['user_id','item_category'],values=['hours'],aggfunc=[np.min,np.max])\n",
    "    max_touchtype = pd.pivot_table(beforeoneday,index=['user_id','item_category'],values=['behavior_type'],aggfunc=np.max)\n",
    "    user_cate_feture = pd.merge(user_item_count,beforeonedayuser_item_count,how='left',right_index=True,left_index=True)\n",
    "    user_cate_feture = pd.merge(user_cate_feture,max_touchtime,how='left',right_index=True,left_index=True)\n",
    "    user_cate_feture = pd.merge(user_cate_feture,max_touchtype,how='left',right_index=True,left_index=True)\n",
    "#    user_cate_feture = pd.merge(user_cate_feture,_live,how='left',right_index=True,left_index=True)\n",
    "    user_cate_feture = pd.merge(user_cate_feture,user_cate_count_5,how='left',right_index=True,left_index=True)\n",
    "    user_cate_feture = pd.merge(user_cate_feture,user_cate_count_3,how='left',right_index=True,left_index=True)\n",
    "    user_cate_feture = pd.merge(user_cate_feture,user_cate_count_2,how='left',right_index=True,left_index=True)\n",
    "    user_cate_feture.fillna(0,inplace=True)\n",
    "    return user_cate_feture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelDay = datetime.datetime(2014,12,17,0,0,0)\n",
    "predict_set_flag = True\n",
    "#predict_set_flag = False #means get train data set\n",
    "if __name__ == '__main__':\n",
    "    result=[]\n",
    "    feature_u = [[] for i in range(3)]\n",
    "    ##根据提取特征的时间范围的不同，特征提取窗口的滑动次数也是会相应变化的。\n",
    "    ##另：以双十二为分界线分别单独提取特征;还是以忽略的方式，有待确定（验证）\n",
    "    #window_size = 4#提取特征的时间范围，单位是天\n",
    "    #window_slide_num = 30#特征提取窗口的滑动次数\n",
    "    window_slide_num = [7,7,7]\n",
    "    print(LabelDay)\n",
    "    #for i in list(range(window_size))[1:]:\n",
    "\n",
    "    for i in [1,3,6]:\n",
    "        k=1\n",
    "        print('特征窗口的size：', i, '天')\n",
    "        if(predict_set_flag):\n",
    "            LabelDay = datetime.datetime(2014,12,17,0,0,0)\n",
    "            train_data_set_dir_and_file_name = '../DataSet/'+'predict_data_set'+str(i)+'.csv'\n",
    "            window_slide_num = [7]\n",
    "        else:\n",
    "            LabelDay = datetime.datetime(2014,12,10,0,0,0)\n",
    "            train_data_set_dir_and_file_name = '../DataSet/'+'train_data_set'+str(i)+'.csv'\n",
    "        #for j in list(range(window_slide_num)):\n",
    "        for j in window_slide_num:   \n",
    "            start_day = (LabelDay - datetime.timedelta(days=i))    \n",
    "            '''\n",
    "            #暂时不考虑剔除12.11和12.12两天的数据\n",
    "            if ((start_day <= datetime.datetime(2014,12,12,0,0,0)) & (LabelDay > datetime.datetime(2014,12,12,0,0,0))):\n",
    "                #user_behavior_data = Data[(Data['daystime'] >= (LabelDay - datetime.timedelta(days=i))) & (Data['daystime'] < LabelDay)]\n",
    "                LabelDay = datetime.datetime(2014,12,10,0,0,0)\n",
    "                start_day = LabelDay - datetime.timedelta(days=i)   \n",
    "                user_behavior_data = Data[(Data['daystime'] >= start_day) & (Data['daystime'] < LabelDay)]\n",
    "                label_day_data = Data[Data['daystime']==LabelDay]\n",
    "                \n",
    "            else:\n",
    "                user_behavior_data = Data[(Data['daystime'] >= start_day) & (Data['daystime'] < LabelDay)]\n",
    "                label_day_data = Data[Data['daystime']==LabelDay]\n",
    "            '''\n",
    "            '''\n",
    "            if(start_day>=datetime.datetime(2014,11,18,0,0,0)):\n",
    "                user_behavior_data = Data[(Data['daystime'] >= start_day) & (Data['daystime'] < LabelDay)]\n",
    "                label_day_data = Data[Data['daystime']==LabelDay]\n",
    "            else:\n",
    "                print('end')\n",
    "                break\n",
    "            '''\n",
    "            #剔除 12.11和12.12的两天的数据\n",
    "            if(start_day>=datetime.datetime(2014,11,18,0,0,0)):\n",
    "                if(start_day == datetime.datetime(2014,12,12,0,0,0) or (start_day == datetime.datetime(2014,12,11,0,0,0))):\n",
    "                    LabelDay = datetime.datetime(2014,12,10,0,0,0)\n",
    "                    start_day = (LabelDay - datetime.timedelta(days=i))    \n",
    "                    print('窗口的位置：[', start_day, LabelDay ,')')\n",
    "                print('窗口的位置：[', start_day, LabelDay ,')')   \n",
    "                user_behavior_data = Data[(Data['daystime'] >= start_day) & (Data['daystime'] < LabelDay)]\n",
    "                label_data_set = Data[(Data['daystime'] >= start_day) & (Data['daystime'] <= LabelDay)]\n",
    "                #label_day_data = Data[Data['daystime']==LabelDay]\n",
    "            else:\n",
    "                print('end')\n",
    "                break            \n",
    "            #train_user_window1 = Data[(Data['daystime'] > (LabelDay - datetime.timedelta(days=FEATURE_EXTRACTION_SLOT))) & (Data['daystime'] < LabelDay)]\n",
    "            #beforeoneday = Data[Data['daystime'] == (LabelDay-datetime.timedelta(days=1))]\n",
    "            #print(beforeoneday)\n",
    "            # beforetwoday = Data[(Data['daystime'] >= (LabelDay-datetime.timedelta(days=2))) & (Data['daystime'] < LabelDay)]\n",
    "            # beforefiveday = Data[(Data['daystime'] >= (LabelDay-datetime.timedelta(days=5))) & (Data['daystime'] < LabelDay)]\n",
    "            #print(Data.head(5))\n",
    "            #print(user_behavior_data.head(5))\n",
    "            #提取特征部分\n",
    "            #print(user_behavior_data.head(5))\n",
    "            u = get_feature_u(copy.deepcopy(user_behavior_data))\n",
    "            i_i  =  get_feature_i(copy.deepcopy(user_behavior_data))\n",
    "            c =  get_feature_c(copy.deepcopy(user_behavior_data))\n",
    "            ic = get_feature_ic(copy.deepcopy(user_behavior_data))\n",
    "            ui = get_feature_ui(copy.deepcopy(user_behavior_data))\n",
    "            #uc = get_feature_ui(copy.deepcopy(user_behavior_data))\n",
    "            #print(ui.head(5))\n",
    "            \n",
    "            #获取标签日当天的用户购买行为，对a进行打标签\n",
    "            label_data = get_label_set(copy.deepcopy(label_data_set),LabelDay) \n",
    "            #label_data = label_data.head(20)##test\n",
    "            print('label_data:',len(label_data))\n",
    "            #label_data.to_csv('../DataSet/label_data.csv',mode='a',index=None)\n",
    "            #LabelDay = (LabelDay - datetime.timedelta(days=1))    \n",
    "            LabelDay = (LabelDay - datetime.timedelta(days=j))\n",
    "                       \n",
    "            #对数据进行整合，获取train_data_set数据集\n",
    "            #U\n",
    "            label_data.set_index(keys=['user_id'], inplace=True)\n",
    "            label_data.sort_index(inplace=True)\n",
    "            #print(label_data.head(10))\n",
    "            u.set_index(keys=['user_id'], inplace=True)\n",
    "            u.sort_index(inplace=True)\n",
    "            label_data = label_data.join(u,how='left').fillna(0)\n",
    "            #print('after join u ,label_data:',len(label_data))\n",
    "            # I\n",
    "            label_data.reset_index(inplace=True)\n",
    "            #print(label_data.head(10))\n",
    "            label_data.set_index(keys=['item_id'], inplace=True)\n",
    "            label_data.sort_index(inplace=True)\n",
    "            i_i.set_index(keys=['item_id'], inplace=True)\n",
    "            i_i.sort_index(inplace=True)\n",
    "            label_data = label_data.join(i_i,how='left').fillna(0)\n",
    "            print('after join i ,label_data:',len(label_data))\n",
    "            #C\n",
    "            label_data.reset_index(inplace=True)\n",
    "            label_data.set_index(keys=['item_category'], inplace=True)\n",
    "            label_data.sort_index(inplace=True)\n",
    "            c.set_index(keys=['item_category'], inplace=True)\n",
    "            c.sort_index(inplace=True)\n",
    "            label_data = label_data.join(c,how='left').fillna(0)\n",
    "            print('after join c ,label_data:',len(label_data))\n",
    "            #IC\n",
    "            label_data.reset_index(inplace=True)\n",
    "            label_data.set_index(keys=['item_id','item_category'], inplace=True)\n",
    "            label_data.sort_index(inplace=True)\n",
    "            ic.set_index(keys=['item_id','item_category'], inplace=True)\n",
    "            ic.sort_index(inplace=True)\n",
    "            label_data = label_data.join(ic,how='left').fillna(0)\n",
    "            print('after join ic ,label_data:',len(label_data))\n",
    "            #UI\n",
    "            label_data.reset_index(inplace=True)\n",
    "            label_data.set_index(keys=['item_id','user_id'], inplace=True)\n",
    "            label_data.sort_index(inplace=True)\n",
    "            ui.set_index(keys=['item_id','user_id'], inplace=True)\n",
    "            ui.sort_index(inplace=True)\n",
    "            label_data = label_data.join(ui,how='left').fillna(0)\n",
    "            print('after join ui ,label_data:',len(label_data))\n",
    "            #UC\n",
    "            #waiting to add\n",
    "            \n",
    "            #\n",
    "            label_data.reset_index(inplace=True)\n",
    "            #print(label_data.head(5))\n",
    "            if(k==1):\n",
    "                label_data.to_csv(train_data_set_dir_and_file_name,mode='a',header=True,index=None)\n",
    "                k=k-1\n",
    "            else:\n",
    "                label_data.to_csv(train_data_set_dir_and_file_name,mode='a',header=False,index=None)\n",
    "        del(label_data)\n",
    "    print('hello world!')\n",
    "    if(predict_set_flag):\n",
    "        train_data_set1 = pd.read_csv(\"../DataSet/predict_data_set1.csv\",header='infer')\n",
    "        #train_data_set1[['user_id', 'item_id']] = train_data_set1[['user_id', 'item_id']].astype(str)\n",
    "        print(len(train_data_set1))\n",
    "    \n",
    "        train_data_set2 = pd.read_csv(\"../DataSet/predict_data_set3.csv\",header='infer')\n",
    "        #train_data_set2[['user_id', 'item_id']] = train_data_set2[['user_id', 'item_id']].astype(str)\n",
    "        print(len(train_data_set2))\n",
    "        \n",
    "        train_data_set3 = pd.read_csv(\"../DataSet/predict_data_set6.csv\",header='infer')\n",
    "        #train_data_set3[['user_id', 'item_id']] = train_data_set3[['user_id', 'item_id']].astype(str)\n",
    "        print(len(train_data_set3))\n",
    "    else:\n",
    "        train_data_set1 = pd.read_csv(\"../DataSet/train_data_set1.csv\",header='infer')\n",
    "        #train_data_set1[['user_id', 'item_id']] = train_data_set1[['user_id', 'item_id']].astype(str)\n",
    "        print(len(train_data_set1))\n",
    "        #print(train_data_set1.head(5))\n",
    "        train_data_set2 = pd.read_csv(\"../DataSet/train_data_set3.csv\",header='infer')\n",
    "        #train_data_set2[['user_id', 'item_id']] = train_data_set2[['user_id', 'item_id']].astype(str)\n",
    "        print(len(train_data_set2))\n",
    "        #print(train_data_set2.head(5))\n",
    "       \n",
    "    train_data_set2.rename(columns={'item_id':'item_id','user_id':'user_id', 'item_category':'2_item_category', 'label':'2_label','u_b1_count':'2_u_b1_count',\n",
    "                                                 'u_b2_count':'2_u_b2_count', 'u_b3_count':'2_u_b3_count', 'u_b4_count':'2_u_b4_count', 'u_b_count':'2_u_b_count', 'i_b1_count':'2_i_b1_count',\n",
    "                                                   'i_b2_count':'2_i_b2_count', 'i_b3_count':'2_i_b3_count', 'i_b4_count':'2_i_b4_count', 'i_b_count':'2_i_b_count', 'i_b4_rate':'2_i_b4_rate',\n",
    "                                                   'i_user_num':'2_i_user_num', 'c_b1_count':'2_c_b1_count', 'c_b2_count':'2_c_b2_count', 'c_b3_count':'2_c_b3_count', 'c_b4_count':'2_c_b4_count',\n",
    "                                                   'c_b_count':'2_c_b_count', 'c_b4_rate':'2_c_b4_rate', 'c_user_num':'2_c_user_num', 'ic_sales_num':'2_ic_sales_num', 'ic_user_num':'2_ic_user_num',\n",
    "                                                   'ic_behavior_num':'2_ic_behavior_num', 'ui_sort':'2_ui_sort', 'ui_b1_count':'2_ui_b1_count', 'ui_b2_count':'2_ui_b2_count',\n",
    "                                                   'ui_b3_count':'2_ui_b3_count', 'ui_b4_count':'2_ui_b4_count', 'ui_cumcount':'2_ui_cumcount', 'ui_b_count':'2_ui_b_count',\n",
    "                                    'ui_b2_count_in_6':'2_ui_b2_count_in_6',\n",
    "                                    'ui_b3_count_in_6':'2_ui_b3_count_in_6',\n",
    "                                    'ui_b4_count_in_6':'2_ui_b4_count_in_6'},inplace=True)\n",
    "    print(len(train_data_set2.columns))\n",
    "    print(train_data_set2.columns)\n",
    "    #temp = pd.concat([train_data_set1,train_data_set2],axis=1).fillna(0)\n",
    "    temp = train_data_set2.merge(train_data_set1, how='left', on=['item_id','user_id']).fillna(0)\n",
    "    del(train_data_set1)\n",
    "    del(train_data_set2)\n",
    "    train_data_set3 = pd.read_csv(\"../DataSet/train_data_set6.csv\",header='infer')\n",
    "    #train_data_set3[['user_id', 'item_id']] = train_data_set3[['user_id', 'item_id']].astype(str)\n",
    "    print(len(train_data_set3))\n",
    "    #print(train_data_set3.head(5))\n",
    "    train_data_set3.rename(columns={'item_id':'item_id','user_id':'user_id', 'item_category':'3_item_category', 'label':'3_label','u_b1_count':'3_u_b1_count',\n",
    "                                                 'u_b2_count':'3_u_b2_count', 'u_b3_count':'3_u_b3_count', 'u_b4_count':'3_u_b4_count', 'u_b_count':'3_u_b_count', 'i_b1_count':'3_i_b1_count',\n",
    "                                                   'i_b2_count':'3_i_b2_count', 'i_b3_count':'3_i_b3_count', 'i_b4_count':'3_i_b4_count', 'i_b_count':'3_i_b_count', 'i_b4_rate':'3_i_b4_rate',\n",
    "                                                   'i_user_num':'3_i_user_num', 'c_b1_count':'3_c_b1_count', 'c_b2_count':'3_c_b2_count', 'c_b3_count':'3_c_b3_count', 'c_b4_count':'3_c_b4_count',\n",
    "                                                   'c_b_count':'3_c_b_count', 'c_b4_rate':'3_c_b4_rate', 'c_user_num':'3_c_user_num', 'ic_sales_num':'3_ic_sales_num', 'ic_user_num':'3_ic_user_num',\n",
    "                                                   'ic_behavior_num':'3_ic_behavior_num', 'ui_sort':'3_ui_sort', 'ui_b1_count':'3_ui_b1_count', 'ui_b2_count':'3_ui_b2_count',\n",
    "                                                   'ui_b3_count':'3_ui_b3_count', 'ui_b4_count':'3_ui_b4_count', 'ui_cumcount':'3_ui_cumcount', 'ui_b_count':'3_ui_b_count',\n",
    "                                    'ui_b2_count_in_6':'3_ui_b2_count_in_6',\n",
    "                                    'ui_b3_count_in_6':'3_ui_b3_count_in_6',\n",
    "                                    'ui_b4_count_in_6':'3_ui_b4_count_in_6'},inplace=True)\n",
    "\n",
    "    print(len(train_data_set3.columns))\n",
    "    print(train_data_set3.columns)\n",
    "    #train_data_set = pd.concat([temp,train_data_set3],axis=1).fillna(0)\n",
    "    train_data_set = train_data_set3.merge(temp, how='left', on=['item_id','user_id']).fillna(0)\n",
    "    #print('train_data_set\\n',train_data_set.head(30))\n",
    "    del(train_data_set3)\n",
    "    del(temp)\n",
    "    if(predict_set_flag):\n",
    "        train_data_set.drop(train_data_set.columns[[2,33,34,64,65]], axis=1,inplace=True)\n",
    "        #train_data_set = train_data_set[train_data_set.item_id.isin(list(item_table.item_id))]\n",
    "        train_data_set.rename(columns={\"3_label\":\"label\"},inplace=True)\n",
    "        train_data_set.to_csv(\"../DataSet/predict_set.csv\",index=None)\n",
    "    else:\n",
    "        #train_data_set.to_csv(\"../DataSet/train_data_set_all_columns_name.csv\",index=None)\n",
    "        train_data_set.drop(train_data_set.columns[[0,1,2,33,34,64,65]], axis=1,inplace=True)\n",
    "        train_data_set.rename(columns={\"3_label\":\"label\"},inplace=True)\n",
    "        train_data_set.to_csv(\"../DataSet/train_data_set_all.csv\",index=None)\n",
    "        print(\"train_data_set column name list:\",train_data_set.columns,\"train_data_set column name size:\",len(train_data_set.columns))\n",
    "    del(train_data_set)\n",
    "    print('main function end')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

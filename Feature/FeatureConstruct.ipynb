{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "import time\n",
    "#self function\n",
    "#import Ipynb_importer\n",
    "#import FeatureConstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U用户在一个时间窗口内的浏览(1)、收藏(2)、加购物车(3)、购买(4)的行为次数，总行为次数。\n",
    "#user_behavior_data: 时间窗口内的数据\n",
    "def get_feature_u(user_behavior_data):\n",
    "    user_behavior_data['cumcount'] = user_behavior_data.groupby(['user_id','behavior_type']).cumcount()\n",
    "    #print('user_behavior_data')\n",
    "    #print(user_behavior_data.head(5))\n",
    "    user_behavior_data_u = user_behavior_data.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "    #print('user_behavior_data_u-1')\n",
    "    #print(user_behavior_data_u.head(5))\n",
    "    user_behavior_data_u = pd.get_dummies(user_behavior_data_u['behavior_type']).join(user_behavior_data_u[['user_id','cumcount']])\n",
    "    #print('user_behavior_data_u-2')\n",
    "    #print(user_behavior_data_u.head(5))\n",
    "    user_behavior_data_u.rename(columns = {1:'behavior_type_1',\n",
    "                                                               2:'behavior_type_2',\n",
    "                                                               3:'behavior_type_3',\n",
    "                                                               4:'behavior_type_4'}, inplace=True)\n",
    "    #print('user_behavior_data_u-3')\n",
    "    #print(user_behavior_data_u.head(5))\n",
    "    user_behavior_data_u['u_b1_count'] = user_behavior_data_u['behavior_type_1'] * (user_behavior_data_u['cumcount']+1)\n",
    "    user_behavior_data_u['u_b2_count'] = user_behavior_data_u['behavior_type_2'] * (user_behavior_data_u['cumcount']+1)\n",
    "    user_behavior_data_u['u_b3_count'] = user_behavior_data_u['behavior_type_3'] * (user_behavior_data_u['cumcount']+1)\n",
    "    user_behavior_data_u['u_b4_count'] = user_behavior_data_u['behavior_type_4'] * (user_behavior_data_u['cumcount']+1)\n",
    "    #print('user_behavior_data_u-4')\n",
    "    #print(user_behavior_data_u.head(5))\n",
    "    #这步没做什么，实质是进行了列的选取\n",
    "    user_behavior_data_u = user_behavior_data_u.groupby('user_id').agg({'u_b1_count': np.sum,\n",
    "                                                                                                      'u_b2_count': np.sum, \n",
    "                                                                                                      'u_b3_count': np.sum, \n",
    "                                                                                                      'u_b4_count': np.sum})\n",
    "    #print('user_behavior_data_u-5')\n",
    "    #print(user_behavior_data_u.head(5))\n",
    "\n",
    "    user_behavior_data_u.reset_index(inplace = True)\n",
    "    user_behavior_data_u['u_b_count'] = user_behavior_data_u[['u_b1_count',\n",
    "                                                                                        'u_b2_count',\n",
    "                                                                                        'u_b3_count',\n",
    "                                                                                        'u_b4_count']].apply(lambda x: x.sum(), axis = 1)\n",
    "    user_behavior_data_u['u_b4_rate'] = user_behavior_data_u['u_b4_count'] / user_behavior_data_u['u_b_count']\n",
    "    \n",
    "    # u_b4_diff_time\n",
    "    user_behavior_data = user_behavior_data.sort_values(by = ['user_id', 'time'])\n",
    "    user_behavior_data_u_b4_time = user_behavior_data[user_behavior_data['behavior_type'] == 4].drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
    "    user_behavior_data_u_b4_time.columns = ['user_id','b4_first_time']\n",
    "    user_behavior_data_u_b_time = user_behavior_data.drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
    "    user_behavior_data_u_b_time.columns = ['user_id','b_first_time']\n",
    "    user_behavior_data_u_b4_time = pd.merge(user_behavior_data_u_b_time, user_behavior_data_u_b4_time, on = ['user_id'])\n",
    "    user_behavior_data_u_b4_time['u_b4_diff_time'] = user_behavior_data_u_b4_time['b4_first_time'] - user_behavior_data_u_b4_time['b_first_time']\n",
    "    user_behavior_data_u_b4_time = user_behavior_data_u_b4_time[['user_id', 'u_b4_diff_time']]\n",
    "    #lambda x: x.days * 24 + x.seconds//3600 这个有问题吧？\n",
    "    user_behavior_data_u_b4_time['u_b4_diff_hours'] = user_behavior_data_u_b4_time['u_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600) \n",
    "    user_behavior_data_u = pd.merge(user_behavior_data_u, user_behavior_data_u_b4_time, on=['user_id'], how='left')[['user_id',\n",
    "                                                                                                                                                                   'u_b1_count',\n",
    "                                                                                                                                                                   'u_b2_count', \n",
    "                                                                                                                                                                   'u_b3_count',\n",
    "                                                                                                                                                                   'u_b4_count', \n",
    "                                                                                                                                                                   'u_b_count', \n",
    "                                                                                                                                                                   'u_b4_rate', \n",
    "                                                                                                                                                                   'u_b4_diff_hours']]\n",
    "    #print('user_behavior_data_u-6')\n",
    "    #print(user_behavior_data_u.head(5))\n",
    "    return user_behavior_data_u\n",
    "\n",
    "#I商品在目标日前6天的各类行为总数、总行为次数、商品的点击购买转化率、商品的点击购买平均时差、被访问人数。\n",
    "def get_feature_i(user_behavior_data):\n",
    "    user_behavior_data_copy = user_behavior_data\n",
    "    user_behavior_data_copy['i_cumcount'] = user_behavior_data_copy.groupby(['item_id','behavior_type']).cumcount()\n",
    "    user_behavior_data_i = user_behavior_data_copy.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','i_cumcount']]\n",
    "    user_behavior_data_i = pd.get_dummies(user_behavior_data_i['behavior_type']).join(user_behavior_data_i[['item_id','i_cumcount']])\n",
    "    user_behavior_data_i.rename(columns = {1:'i_behavior_type_1',\n",
    "                                           2:'i_behavior_type_2',\n",
    "                                           3:'i_behavior_type_3',\n",
    "                                           4:'i_behavior_type_4'}, inplace=True)\n",
    "    ##各类行为次数\n",
    "    user_behavior_data_i['i_b1_count'] = user_behavior_data_i['i_behavior_type_1'] * (user_behavior_data_i['i_cumcount']+1)\n",
    "    user_behavior_data_i['i_b2_count'] = user_behavior_data_i['i_behavior_type_2'] * (user_behavior_data_i['i_cumcount']+1)\n",
    "    user_behavior_data_i['i_b3_count'] = user_behavior_data_i['i_behavior_type_3'] * (user_behavior_data_i['i_cumcount']+1)\n",
    "    user_behavior_data_i['i_b4_count'] = user_behavior_data_i['i_behavior_type_4'] * (user_behavior_data_i['i_cumcount']+1)\n",
    "    ##这步其实没做什么，实质是进行了列的选取\n",
    "    user_behavior_data_i = user_behavior_data_i.groupby('item_id').agg({'i_b1_count': np.sum,\n",
    "                                                                                                    'i_b2_count': np.sum, \n",
    "                                                                                                    'i_b3_count': np.sum, \n",
    "                                                                                                    'i_b4_count': np.sum})\n",
    "    user_behavior_data_i.reset_index(inplace = True)\n",
    "    ##总行为次数\n",
    "    user_behavior_data_i['i_b_count'] = user_behavior_data_i[['i_b1_count',\n",
    "                                                                                     'i_b2_count',\n",
    "                                                                                     'i_b3_count',\n",
    "                                                                                     'i_b4_count']].apply(lambda x: x.sum(), axis = 1)\n",
    "    ##商品点击购买转化率\n",
    "    user_behavior_data_i['i_b4_rate'] = user_behavior_data_i['i_b4_count'] / user_behavior_data_i['i_b_count']\n",
    "    \n",
    "    ##被访问人数\n",
    "    item_user_group_size = pd.DataFrame(user_behavior_data.groupby(['item_id','user_id']).size())\n",
    "    item_user_num = pd.DataFrame(item_user_group_size.groupby(['item_id']).size())\n",
    "    item_user_num.rename(columns = {0:'i_user_num'},inplace=True)\n",
    "    user_behavior_data_i=user_behavior_data_i.set_index('item_id')\n",
    "    user_behavior_data_i = user_behavior_data_i.join(item_user_num)\n",
    "    user_behavior_data_i.reset_index(inplace = True)\n",
    "    ##\n",
    "    ##商品点击购买平均时差（非常重要）；不用的人对同一个商品的时差不一致，需要平均。另外这个购买平均时差的特征加持在人身上效果应该会更好，\n",
    "    # i_b4_diff_time\n",
    "    user_behavior_data = user_behavior_data.sort_values(by=['item_id', 'time'])\n",
    "    user_behavior_data_i_b4_time = user_behavior_data[user_behavior_data['behavior_type'] == 4].drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
    "    user_behavior_data_i_b4_time.columns = ['item_id','b4_first_time']\n",
    "    user_behavior_data_i_b_time = user_behavior_data.drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
    "    user_behavior_data_i_b_time.columns = ['item_id','b_first_time']\n",
    "    user_behavior_data_i_b4_time = pd.merge(user_behavior_data_i_b_time, user_behavior_data_i_b4_time, on = ['item_id'])\n",
    "    user_behavior_data_i_b4_time['i_b4_diff_time']  = user_behavior_data_i_b4_time['b4_first_time'] - user_behavior_data_i_b4_time['b_first_time']\n",
    "    #lambda x: x.days * 24 + x.seconds//3600 这个有问题吧？\n",
    "    user_behavior_data_i_b4_time['i_b4_diff_hours'] = user_behavior_data_i_b4_time['i_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n",
    "    user_behavior_data_i_b4_time = user_behavior_data_i_b4_time[['item_id', 'i_b4_diff_hours']]\n",
    "    \n",
    "    user_behavior_data_i = pd.merge(user_behavior_data_i, user_behavior_data_i_b4_time, on=['item_id'], how='left')[['item_id',\n",
    "                                                                                                                                                                   'i_b1_count',\n",
    "                                                                                                                                                                   'i_b2_count', \n",
    "                                                                                                                                                                   'i_b3_count',\n",
    "                                                                                                                                                                   'i_b4_count', \n",
    "                                                                                                                                                                   'i_b_count', \n",
    "                                                                                                                                                                   'i_b4_rate', \n",
    "                                                                                                                                                                   'i_user_num',\n",
    "                                                                                                                                                                   'i_b4_diff_hours']]  \n",
    "    return user_behavior_data_i\n",
    "\n",
    "#C类目在目标日前6天的各类行为总数、总行为次数、商品的点击购买转化率、商品的点击购买平均时差、被访问人数。\n",
    "def get_feature_c(user_behavior_data):\n",
    "    user_behavior_data_copy = user_behavior_data\n",
    "    #df_part_1_c_b = df_part_1_u_b\n",
    "    user_behavior_data_copy['c_cumcount'] = user_behavior_data_copy.groupby(['item_category','behavior_type']).cumcount()\n",
    "    user_behavior_data_c = user_behavior_data_copy.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','c_cumcount']]\n",
    "    user_behavior_data_c = pd.get_dummies(user_behavior_data_c['behavior_type']).join(user_behavior_data_c[['item_category','c_cumcount']])\n",
    "    user_behavior_data_c.rename(columns = {1:'c_behavior_type_1',\n",
    "                                           2:'c_behavior_type_2',\n",
    "                                           3:'c_behavior_type_3',\n",
    "                                           4:'c_behavior_type_4'}, inplace=True)\n",
    "    ##各类行为次数\n",
    "    user_behavior_data_c['c_b1_count'] = user_behavior_data_c['c_behavior_type_1'] * (user_behavior_data_c['c_cumcount']+1)\n",
    "    user_behavior_data_c['c_b2_count'] = user_behavior_data_c['c_behavior_type_2'] * (user_behavior_data_c['c_cumcount']+1)\n",
    "    user_behavior_data_c['c_b3_count'] = user_behavior_data_c['c_behavior_type_3'] * (user_behavior_data_c['c_cumcount']+1)\n",
    "    user_behavior_data_c['c_b4_count'] = user_behavior_data_c['c_behavior_type_4'] * (user_behavior_data_c['c_cumcount']+1)\n",
    "    ##这步其实没做什么，实质是进行了列的选取\n",
    "    user_behavior_data_c = user_behavior_data_c.groupby('item_category').agg({'c_b1_count': np.sum,\n",
    "                                                                                  'c_b2_count': np.sum, \n",
    "                                                                                  'c_b3_count': np.sum, \n",
    "                                                                                  'c_b4_count': np.sum})\n",
    "    user_behavior_data_c.reset_index(inplace = True)\n",
    "    ##总行为次数\n",
    "    user_behavior_data_c['c_b_count'] = user_behavior_data_c[['c_b1_count',\n",
    "                                                                       'c_b2_count',\n",
    "                                                                       'c_b3_count',\n",
    "                                                                       'c_b4_count']].apply(lambda x: x.sum(), axis = 1)\n",
    "    ##商品点击购买转化率\n",
    "    user_behavior_data_c['c_b4_rate'] = user_behavior_data_c['c_b4_count'] / user_behavior_data_c['c_b_count']\n",
    "    \n",
    "    ##被访问人数\n",
    "    category_user_group_size = pd.DataFrame(user_behavior_data_copy.groupby(['item_category','user_id']).size())\n",
    "    category_user_num = pd.DataFrame(category_user_group_size.groupby(['item_category']).size())\n",
    "    category_user_num.rename(columns = {0:'c_user_num'},inplace=True)\n",
    "    user_behavior_data_c=user_behavior_data_c.set_index(['item_category'])\n",
    "    user_behavior_data_c = user_behavior_data_c.join(category_user_num)\n",
    "    user_behavior_data_c.reset_index(inplace = True)\n",
    "\n",
    "    ##商品点击购买平均时差（非常重要）；不用的人对同一个商品的时差不一致，需要平均。另外这个购买平均时差的特征加持在人身上效果应该会更好，\n",
    "    user_behavior_data = user_behavior_data.sort_values(by=['item_category', 'time'])\n",
    "    user_behavior_data_c_b4_time = user_behavior_data[user_behavior_data['behavior_type'] == 4].drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
    "    user_behavior_data_c_b4_time.columns = ['item_category','b4_first_time']\n",
    "    user_behavior_data_c_b_time = user_behavior_data.drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
    "    user_behavior_data_c_b_time.columns = ['item_category','b_first_time']\n",
    "    user_behavior_data_c_b_b4_time = pd.merge(user_behavior_data_c_b_time, user_behavior_data_c_b4_time, on = ['item_category'])\n",
    "    user_behavior_data_c_b_b4_time['c_b4_diff_time']  = user_behavior_data_c_b_b4_time['b4_first_time'] - user_behavior_data_c_b_b4_time['b_first_time']\n",
    "    user_behavior_data_c_b_b4_time['c_b4_diff_hours'] = user_behavior_data_c_b_b4_time['c_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n",
    "    user_behavior_data_c_b_b4_time = user_behavior_data_c_b_b4_time[['item_category','c_b4_diff_hours']]\n",
    "    user_behavior_data_c = pd.merge(user_behavior_data_c, user_behavior_data_c_b_b4_time, on=['item_category'], how='left')[['item_category',\n",
    "                                                                                                                                                                                   'c_b1_count',\n",
    "                                                                                                                                                                                   'c_b2_count', \n",
    "                                                                                                                                                                                   'c_b3_count',\n",
    "                                                                                                                                                                                   'c_b4_count', \n",
    "                                                                                                                                                                                   'c_b_count', \n",
    "                                                                                                                                                                                   'c_b4_rate', \n",
    "                                                                                                                                                                                   'c_user_num',\n",
    "                                                                                                                                                                                   'c_b4_diff_hours']]  \n",
    "    return user_behavior_data_c\n",
    "\n",
    "#IC商品在所属类别中的用户人数(排序)、商品在所属类别中的行为总数(排序)、商品在所属类别中的销量排序\n",
    "def get_feature_ic(user_behavior_data): \n",
    "    user_behavior_data_uic = user_behavior_data.drop_duplicates(['user_id','item_id','item_category'], 'first')\n",
    "    user_behavior_data_i = get_feature_i(user_behavior_data)\n",
    "    user_behavior_data_i_ub_count = user_behavior_data_i[['item_id','i_user_num','i_b_count','i_b4_count']]\n",
    "    \n",
    "    user_behavior_data_ic_ub_count = pd.merge(user_behavior_data_uic, user_behavior_data_i_ub_count, on=['item_id'], how='left').fillna(0)\n",
    "    user_behavior_data_ic_ub_count = user_behavior_data_ic_ub_count.drop_duplicates(['item_id','item_category'])\n",
    "\n",
    "    # ic_u_rank_in_c\n",
    "    user_behavior_data_ic_ub_count['ic_u_rank_in_c'] = user_behavior_data_ic_ub_count.groupby('item_category')['i_user_num'].rank(method='min',ascending=False).astype('int')\n",
    "    # ic_b_rank_in_c                \n",
    "    user_behavior_data_ic_ub_count['ic_b_rank_in_c'] = user_behavior_data_ic_ub_count.groupby('item_category')['i_b_count'].rank(method='min',ascending=False).astype('int')\n",
    "    # ic_b4_rank_in_c\n",
    "    user_behavior_data_ic_ub_count['ic_b4_rank_in_c'] = user_behavior_data_ic_ub_count.groupby('item_category')['i_b4_count'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "    user_behavior_data_ic = user_behavior_data_ic_ub_count[['item_id', \n",
    "                                                                                      'item_category', \n",
    "                                                                                      'ic_u_rank_in_c', \n",
    "                                                                                      'ic_b_rank_in_c', \n",
    "                                                                                      'ic_b4_rank_in_c']]\n",
    "\n",
    "    '''user_behavior_data_copy = user_behavior_data\n",
    "    ##商品在所属类别中的用户人数\n",
    "    item_category_user_size = pd.DataFrame(user_behavior_data_copy.groupby(['item_id','item_category','user_id']).size())\n",
    "    item_category_user_num = pd.DataFrame(item_category_user_size.groupby(['item_id','item_category']).size())\n",
    "    item_category_user_num.rename(columns = {0:'ic_user_num'},inplace=True)\n",
    "    #print(item_category_user_num.head(5))\n",
    "    \n",
    "    ##商品在所属类别中的行为总数\n",
    "    item_category_behavior_size = pd.DataFrame(user_behavior_data_copy.groupby(['item_id','item_category']).size())\n",
    "    item_category_behavior_size.rename(columns = {0:'ic_behavior_num'},inplace=True)\n",
    "    #print('1:',item_category_behavior_size.head(5))\n",
    "    \n",
    "    ##商品在所属类别中的销量排序\n",
    "    item_category_behavior_sales_size = pd.DataFrame(user_behavior_data_copy.groupby(['item_id','item_category','behavior_type']).size())\n",
    "    item_category_behavior_sales_size = item_category_behavior_sales_size.reset_index()\n",
    "    #print('2:',item_category_behavior_sales_size.head(5))\n",
    "    user_behavior_data_ic = item_category_behavior_sales_size[item_category_behavior_sales_size.behavior_type==4]\n",
    "    user_behavior_data_ic.rename(columns = {0:'ic_sales_num'},inplace=True)\n",
    "    user_behavior_data_ic.set_index(['item_id','item_category'],inplace=True)\n",
    "    #print('3:',df_part_1_ic_b_count_in_6.head(5))\n",
    "    user_behavior_data_ic = user_behavior_data_ic.join(item_category_user_num,how='outer')\n",
    "    user_behavior_data_ic = user_behavior_data_ic.join(item_category_behavior_size,how='outer')\n",
    "    user_behavior_data_ic = user_behavior_data_ic[['ic_sales_num','ic_user_num','ic_behavior_num']].fillna(0)\n",
    "    #df_part_1_ic_b_count_in_6\n",
    "    user_behavior_data_ic.reset_index(inplace = True)'''\n",
    "    return user_behavior_data_ic\n",
    "\n",
    "    \n",
    "#UI用户-商品对在考察日前6天的行为总数计数、用户-商品对在考察日前6天的各项行为计数、\n",
    "#用户-商品对各项行为上一次发生距考察日的时差、用户商品对的行为在用户所有商品中的排序\n",
    "def get_feature_ui(user_behavior_data,end_day):  \n",
    "    end_day = str(end_day)\n",
    "    #df_part_1_ui_b = df_part_1_u_b\n",
    "    user_behavior_data_copy = user_behavior_data\n",
    "    \n",
    "    ui_b_count_size = pd.DataFrame(user_behavior_data_copy.groupby(['item_id','user_id','behavior_type']).size())\n",
    "    ui_b_count_size = ui_b_count_size.reset_index()\n",
    "    ui_b_count_size.rename(columns={0:'ui_cumcount'},inplace=True)\n",
    "    ui_b_count_num = pd.get_dummies(ui_b_count_size['behavior_type']).join(ui_b_count_size[['user_id','item_id','ui_cumcount']])\n",
    "    ui_b_count_num.rename(columns={1:'ui_b1_count',\n",
    "                                        2:'ui_b2_count',\n",
    "                                        3:'ui_b3_count',\n",
    "                                        4:'ui_b4_count'},inplace=True)\n",
    "    ##用户-商品对在考察日前n天的各项行为计数\n",
    "    ui_b_count_num['ui_b1_count'] = ui_b_count_num['ui_b1_count'] * ui_b_count_num['ui_cumcount']\n",
    "    ui_b_count_num['ui_b2_count'] = ui_b_count_num['ui_b2_count'] * ui_b_count_num['ui_cumcount']\n",
    "    ui_b_count_num['ui_b3_count'] = ui_b_count_num['ui_b3_count'] * ui_b_count_num['ui_cumcount']\n",
    "    ui_b_count_num['ui_b4_count'] = ui_b_count_num['ui_b4_count'] * ui_b_count_num['ui_cumcount']\n",
    "    ##用户-商品对在考察日前n天的行为总数计数\n",
    "    ui_b_count_num['ui_b_count']= ui_b_count_num['ui_b1_count'] + ui_b_count_num['ui_b2_count'] + ui_b_count_num['ui_b3_count'] + ui_b_count_num['ui_b4_count']\n",
    "    ui_b_count_num = ui_b_count_num.groupby(['item_id','user_id']).sum()\n",
    "    \n",
    "    user_behavior_data_ui = ui_b_count_num[['ui_b1_count',\n",
    "                                                               'ui_b2_count',\n",
    "                                                               'ui_b3_count',\n",
    "                                                               'ui_b4_count',\n",
    "                                                               'ui_b_count']].astype(int)\n",
    "    ##用户-商品对的行为在本用户所有用户-商品对中的排序\n",
    "    user_behavior_data_ui['ui_b_count_rank_in_u'] = user_behavior_data_ui.groupby(['user_id'])['ui_b_count'].rank(method='min',ascending=False).astype('int')\n",
    "    '''\n",
    "    user_behavior_data_ui = user_behavior_data_ui.sort_values(by='ui_b_count',ascending=True)\n",
    "    temp = pd.DataFrame(user_behavior_data_ui.groupby(['user_id']).cumcount())\n",
    "    user_behavior_data_ui = temp.join(ui_b_count_num)\n",
    "    user_behavior_data_ui.rename(columns={0:'ui_sort'},inplace=True)\n",
    "    user_behavior_data_ui['ui_sort'] = user_behavior_data_ui['ui_sort']+1\n",
    "    user_behavior_data_ui.reset_index(inplace = True)    \n",
    "    '''\n",
    "    #UI\n",
    "    user_behavior_data_uic = user_behavior_data.drop_duplicates(['user_id','item_id','item_category'], 'first')\n",
    "    user_behavior_data_ui = pd.merge(user_behavior_data_uic, user_behavior_data_ui, on = ['user_id','item_id'], how = 'left')\n",
    "    ###UI-UC特征\n",
    "    user_behavior_data_ui['ui_b_count_rank_in_uc'] = user_behavior_data_ui.groupby(['user_id','item_category'])['ui_b_count_rank_in_u'].rank(method='min',ascending=True).astype('int')\n",
    "    ##用户-商品对各项行为上一次发生距考察日的时差\n",
    "\n",
    "    # ui_b_last_time\n",
    "    user_behavior_data_uic.sort_values(by=['user_id','item_id','behavior_type','time'], inplace=True)\n",
    "    ub_data_ui_b_last_time = user_behavior_data_uic.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','time']]\n",
    "\n",
    "    ub_data_ui_b_last_time['ui_b1_last_time'] = ub_data_ui_b_last_time[ub_data_ui_b_last_time['behavior_type'] == 1]['time']\n",
    "    ub_data_ui_b_last_time['ui_b2_last_time'] = ub_data_ui_b_last_time[ub_data_ui_b_last_time['behavior_type'] == 2]['time']\n",
    "    ub_data_ui_b_last_time['ui_b3_last_time'] = ub_data_ui_b_last_time[ub_data_ui_b_last_time['behavior_type'] == 3]['time']\n",
    "    ub_data_ui_b_last_time['ui_b4_last_time'] = ub_data_ui_b_last_time[ub_data_ui_b_last_time['behavior_type'] == 4]['time']\n",
    "\n",
    "    ub_data_ui_b_last_time.loc[ub_data_ui_b_last_time['ui_b1_last_time'].notnull(), 'ui_b1_last_hours'] = (pd.to_datetime(end_day) - ub_data_ui_b_last_time['ui_b1_last_time'])             \n",
    "    ub_data_ui_b_last_time['ui_b1_last_hours'] = ub_data_ui_b_last_time[ub_data_ui_b_last_time['ui_b1_last_hours'].notnull()]['ui_b1_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "    ub_data_ui_b_last_time.loc[ub_data_ui_b_last_time['ui_b2_last_time'].notnull(), 'ui_b2_last_hours'] = (pd.to_datetime(end_day) - ub_data_ui_b_last_time['ui_b2_last_time'])             \n",
    "    ub_data_ui_b_last_time['ui_b2_last_hours'] = ub_data_ui_b_last_time[ub_data_ui_b_last_time['ui_b2_last_hours'].notnull()]['ui_b2_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "    ub_data_ui_b_last_time.loc[ub_data_ui_b_last_time['ui_b3_last_time'].notnull(), 'ui_b3_last_hours'] = (pd.to_datetime(end_day) - ub_data_ui_b_last_time['ui_b3_last_time'])             \n",
    "    ub_data_ui_b_last_time['ui_b3_last_hours'] = ub_data_ui_b_last_time[ub_data_ui_b_last_time['ui_b3_last_hours'].notnull()]['ui_b3_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "    ub_data_ui_b_last_time.loc[ub_data_ui_b_last_time['ui_b4_last_time'].notnull(), 'ui_b4_last_hours'] = (pd.to_datetime(end_day) - ub_data_ui_b_last_time['ui_b4_last_time'])             \n",
    "    ub_data_ui_b_last_time['ui_b4_last_hours'] = ub_data_ui_b_last_time[ub_data_ui_b_last_time['ui_b4_last_hours'].notnull()]['ui_b4_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "    ub_data_ui_b_last_time = ub_data_ui_b_last_time[['user_id',\n",
    "                                                                         'item_id',\n",
    "                                                                         'ui_b1_last_hours',\n",
    "                                                                         'ui_b2_last_hours',\n",
    "                                                                         'ui_b3_last_hours',\n",
    "                                                                         'ui_b4_last_hours']] \n",
    "\n",
    "    ub_data_ui_b_last_time = ub_data_ui_b_last_time.groupby(['user_id', 'item_id']).agg({'ui_b1_last_hours': np.sum,\n",
    "                                                                                                                         'ui_b2_last_hours': np.sum,\n",
    "                                                                                                                         'ui_b3_last_hours': np.sum,\n",
    "                                                                                                                         'ui_b4_last_hours': np.sum})\n",
    "    ub_data_ui_b_last_time.reset_index(inplace = True)\n",
    "    \n",
    "    user_behavior_data_ui = pd.merge(user_behavior_data_ui, ub_data_ui_b_last_time, how='left', on=['user_id', 'item_id'])\n",
    "    user_behavior_data_ui = user_behavior_data_ui[['user_id',\n",
    "                                                                        'item_id',\n",
    "                                                                        'ui_b1_count',\n",
    "                                                                        'ui_b2_count',\n",
    "                                                                        'ui_b3_count',\n",
    "                                                                        'ui_b4_count',\n",
    "                                                                        'ui_b_count',\n",
    "                                                                        'ui_b_count_rank_in_u',\n",
    "                                                                        'ui_b_count_rank_in_uc',\n",
    "                                                                        'ui_b1_last_hours',\n",
    "                                                                        'ui_b2_last_hours',\n",
    "                                                                        'ui_b3_last_hours',\n",
    "                                                                        'ui_b4_last_hours']]\n",
    "    return user_behavior_data_ui\n",
    "\n",
    "#\n",
    "def get_feature_uc(user_behavior_data,end_day):  \n",
    "    end_day = str(end_day)\n",
    "    user_behavior_data['cumcount'] = user_behavior_data.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
    "    uc_b_count = user_behavior_data.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n",
    "    uc_b_count = pd.get_dummies(uc_b_count['behavior_type']).join(uc_b_count[['user_id','item_category','cumcount']])\n",
    "    uc_b_count.rename(columns = {1:'behavior_type_1',\n",
    "                                                2:'behavior_type_2',\n",
    "                                                3:'behavior_type_3',\n",
    "                                                4:'behavior_type_4'}, inplace=True)  \n",
    "    uc_b_count['uc_b1_count'] = uc_b_count['behavior_type_1'] * (uc_b_count['cumcount']+1)\n",
    "    uc_b_count['uc_b2_count'] = uc_b_count['behavior_type_2'] * (uc_b_count['cumcount']+1)\n",
    "    uc_b_count['uc_b3_count'] = uc_b_count['behavior_type_3'] * (uc_b_count['cumcount']+1)\n",
    "    uc_b_count['uc_b4_count'] = uc_b_count['behavior_type_4'] * (uc_b_count['cumcount']+1)\n",
    "    \n",
    "    uc_b_count = uc_b_count.groupby(['user_id', 'item_category']).agg({'uc_b1_count': np.sum,\n",
    "                                                                                                 'uc_b2_count': np.sum,\n",
    "                                                                                                 'uc_b3_count': np.sum,\n",
    "                                                                                                 'uc_b4_count': np.sum})\n",
    "    uc_b_count.reset_index(inplace = True)\n",
    "    uc_b_count['uc_b_count'] = uc_b_count['uc_b1_count'] + uc_b_count['uc_b2_count'] + uc_b_count['uc_b3_count'] + uc_b_count['uc_b4_count']\n",
    "    user_behavior_data_uc = uc_b_count[['user_id',\n",
    "                                                        'item_category',\n",
    "                                                        'uc_b1_count',\n",
    "                                                        'uc_b2_count',\n",
    "                                                        'uc_b3_count',\n",
    "                                                        'uc_b4_count',\n",
    "                                                        'uc_b_count']]\n",
    "    # uc_b_count_rank_in_u\n",
    "    user_behavior_data_uc['uc_b_count_rank_in_u'] = user_behavior_data_uc.groupby(['user_id'])['uc_b_count'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "    # uc_b_last_time\n",
    "    #user_behavior_data_uic = user_behavior_data.drop_duplicates(['user_id','item_id','item_category'], 'first')\n",
    "    user_behavior_data.sort_values(by=['user_id','item_category','behavior_type','time'], inplace=True)\n",
    "    ub_data_uc_b_last_time = user_behavior_data.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','time']]\n",
    "\n",
    "    ub_data_uc_b_last_time['uc_b1_last_time'] = ub_data_uc_b_last_time[ub_data_uc_b_last_time['behavior_type'] == 1]['time']\n",
    "    ub_data_uc_b_last_time['uc_b2_last_time'] = ub_data_uc_b_last_time[ub_data_uc_b_last_time['behavior_type'] == 2]['time']\n",
    "    ub_data_uc_b_last_time['uc_b3_last_time'] = ub_data_uc_b_last_time[ub_data_uc_b_last_time['behavior_type'] == 3]['time']\n",
    "    ub_data_uc_b_last_time['uc_b4_last_time'] = ub_data_uc_b_last_time[ub_data_uc_b_last_time['behavior_type'] == 4]['time']\n",
    "\n",
    "    ub_data_uc_b_last_time.loc[ub_data_uc_b_last_time['uc_b1_last_time'].notnull(), 'uc_b1_last_hours'] = (pd.to_datetime(end_day) - ub_data_uc_b_last_time['uc_b1_last_time'])             \n",
    "    ub_data_uc_b_last_time['uc_b1_last_hours'] = ub_data_uc_b_last_time[ub_data_uc_b_last_time['uc_b1_last_hours'].notnull()]['uc_b1_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "    ub_data_uc_b_last_time.loc[ub_data_uc_b_last_time['uc_b2_last_time'].notnull(), 'uc_b2_last_hours'] = (pd.to_datetime(end_day) - ub_data_uc_b_last_time['uc_b2_last_time'])             \n",
    "    ub_data_uc_b_last_time['uc_b2_last_hours'] = ub_data_uc_b_last_time[ub_data_uc_b_last_time['uc_b2_last_hours'].notnull()]['uc_b2_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "    ub_data_uc_b_last_time.loc[ub_data_uc_b_last_time['uc_b3_last_time'].notnull(), 'uc_b3_last_hours'] = (pd.to_datetime(end_day) - ub_data_uc_b_last_time['uc_b3_last_time'])             \n",
    "    ub_data_uc_b_last_time['uc_b3_last_hours'] = ub_data_uc_b_last_time[ub_data_uc_b_last_time['uc_b3_last_hours'].notnull()]['uc_b3_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "    ub_data_uc_b_last_time.loc[ub_data_uc_b_last_time['uc_b4_last_time'].notnull(), 'uc_b4_last_hours'] = (pd.to_datetime(end_day) - ub_data_uc_b_last_time['uc_b4_last_time'])             \n",
    "    ub_data_uc_b_last_time['uc_b4_last_hours'] = ub_data_uc_b_last_time[ub_data_uc_b_last_time['uc_b4_last_hours'].notnull()]['uc_b4_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "    ub_data_uc_b_last_time = ub_data_uc_b_last_time[['user_id',\n",
    "                                                                             'item_category',\n",
    "                                                                             'uc_b1_last_hours',\n",
    "                                                                             'uc_b2_last_hours',\n",
    "                                                                             'uc_b3_last_hours',\n",
    "                                                                             'uc_b4_last_hours']] \n",
    "\n",
    "    ub_data_uc_b_last_time = ub_data_uc_b_last_time.groupby(['user_id', 'item_category']).agg({'uc_b1_last_hours': np.sum,\n",
    "                                                                                                                                   'uc_b2_last_hours': np.sum,\n",
    "                                                                                                                                   'uc_b3_last_hours': np.sum,\n",
    "                                                                                                                                   'uc_b4_last_hours': np.sum})\n",
    "    ub_data_uc_b_last_time.reset_index(inplace = True)\n",
    "\n",
    "    # merge for generation of f_UC_part_1\n",
    "    user_behavior_data_uc = pd.merge(user_behavior_data_uc, ub_data_uc_b_last_time, how='left', on=['user_id', 'item_category'])\n",
    "    user_behavior_data_uc = user_behavior_data_uc[['user_id',\n",
    "                                                                         'item_category',\n",
    "                                                                         'uc_b1_count',\n",
    "                                                                         'uc_b2_count',\n",
    "                                                                         'uc_b3_count',\n",
    "                                                                         'uc_b4_count',\n",
    "                                                                         'uc_b_count',\n",
    "                                                                         'uc_b_count_rank_in_u',\n",
    "                                                                         'uc_b1_last_hours',\n",
    "                                                                         'uc_b2_last_hours',\n",
    "                                                                         'uc_b3_last_hours',\n",
    "                                                                         'uc_b4_last_hours']]\n",
    "    return user_behavior_data_uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_construct(start_day, end_day, feature_window_size):\n",
    "    start_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    #build file name\n",
    "    second_end_day = (end_day - datetime.timedelta(days=1))    \n",
    "    start_day_str = str(start_day.date())\n",
    "    end_day_str = str(end_day.date())\n",
    "    second_end_day_str = str(second_end_day.date())\n",
    "    print('feature construct from %s  to %s start time:'%(start_day_str,end_day_str), start_time)\n",
    "    name = start_day_str + \"to\" + second_end_day_str\n",
    "    \n",
    "    #input file name\n",
    "    part_data_file_name = \"../DataSet/DevideData/\"+\"part_data\"+name+\".csv\"\n",
    "    #part_data_label_file_name =  \"../DataSet/\"+\"part_data_label\"+end_day_str+\".csv\"\n",
    "    part_data_label_filename =  \"../DataSet/DevideData/\"+\"part_data_uicl\"+end_day_str+\".csv\"\n",
    "    user_behavior_data = pd.read_csv(part_data_file_name,names=['time','user_id','item_id','behavior_type','item_category'],header=None,parse_dates=[0])\n",
    "    user_behavior_data.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "    \n",
    "    \n",
    "    #output file name\n",
    "    train_data_filename = \"../DataSet/Feature/\"+\"part_data_uiclf\"+end_day_str+\".csv\"\n",
    "    #print(user_behavior_data.head(5))\n",
    "    #user_behavior_data_uic_label = pd.read_csv(part_data_label_filename,names=['time','user_id','item_id','behavior_type','item_category'],header=None)\n",
    "    user_behavior_data_uic_label = pd.read_csv(part_data_label_filename)\n",
    "    #print(user_behavior_data_uic_label)\n",
    "    u=list()\n",
    "    i_i=list()\n",
    "    c=list()\n",
    "    ic=list()\n",
    "    ui=list()\n",
    "    uc=list()\n",
    "    for i in list([4,2,1]): \n",
    "        j=0  \n",
    "        start_day = (end_day - datetime.timedelta(days=i))   \n",
    "        end_day = end_day\n",
    "        user_behavior_data = user_behavior_data[user_behavior_data['time'] >= start_day]\n",
    "        \n",
    "        #提取特征部分\n",
    "        u.append(get_feature_u(copy.deepcopy(user_behavior_data)))\n",
    "        i_i.append(get_feature_i(copy.deepcopy(user_behavior_data)))\n",
    "        c.append(get_feature_c(copy.deepcopy(user_behavior_data)))\n",
    "        ic.append(get_feature_ic(copy.deepcopy(user_behavior_data)))\n",
    "        ui.append(get_feature_ui(copy.deepcopy(user_behavior_data),end_day))\n",
    "        uc.append(get_feature_uc(copy.deepcopy(user_behavior_data),end_day))\n",
    "        j+=1\n",
    "        \n",
    "    feature_construct_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print('feature construct  time:', feature_construct_time)\n",
    "    for i in list(range(len(u)))[1:]:\n",
    "        u[0] = pd.merge(u[0], u[i], on = ['user_id'], how = 'left').fillna(0)\n",
    "        i_i[0] = pd.merge(i_i[0], i_i[i], on = ['item_id'], how = 'left').fillna(0)\n",
    "        c[0] = pd.merge(c[0], c[i], on = ['item_category'], how = 'left').fillna(0)\n",
    "        ic[0] = pd.merge(ic[0], ic[i], on = ['item_id','item_category'], how = 'left').fillna(0)\n",
    "        ui[0] = pd.merge(ui[0], ui[i], on = ['user_id','item_id'], how = 'left').fillna(0)\n",
    "        uc[0]= pd.merge(uc[0], uc[i], on = ['user_id','item_category'], how = 'left').fillna(0)\n",
    "        \n",
    "    feature_construct_join_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print('feature construct join time:', feature_construct_join_time)\n",
    "    #这个位置填充的合适的值是什么？   \n",
    "    feature_data = pd.merge(user_behavior_data_uic_label, u[0], how='left', on=['user_id'])\n",
    "    feature_data = pd.merge(feature_data, i_i[0],  how='left', on=['item_id'])\n",
    "    feature_data = pd.merge(feature_data, c[0],  how='left', on=['item_category'])\n",
    "    feature_data = pd.merge(feature_data, ic[0], how='left', on=['item_id','item_category'])\n",
    "    feature_data = pd.merge(feature_data, ui[0], how='left', on=['user_id','item_id'])  \n",
    "    feature_data = pd.merge(feature_data, uc[0], how='left', on=['user_id','item_category'])\n",
    "\n",
    "    feature_data.fillna(-1, inplace=True)# 一个重要的位置###############\n",
    "    \n",
    "    train_data = feature_data\n",
    "    end_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    train_data.to_csv(train_data_filename,index=False)\n",
    "    print('end time:', end_time)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Unit Test As Follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "user_behavior_data_one[user_behavior_data_one.behavior_type==4]\n",
    "user_behavior_data_one.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "end_day = datetime.datetime(2014,12,5,0,0,0)\n",
    "start_day = datetime.datetime(2014,11,29,0,0,0)\n",
    "start_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "#feature_construct(start, end, feature_window_size)\n",
    "#build file name\n",
    "second_end_day = (end_day - datetime.timedelta(days=1))    \n",
    "start_day_str = str(start_day.date())\n",
    "end_day_str = str(end_day.date())\n",
    "second_end_day_str = str(second_end_day.date())\n",
    "print('feature construct from %s  to %s start time:'%(start_day_str,end_day_str), start_time)\n",
    "name = start_day_str + \"to\" + second_end_day_str\n",
    "part_data_file_name = \"../DataSet/DevideData/\"+\"part_data\"+name+\".csv\"\n",
    "\n",
    "user_behavior_data = pd.read_csv(part_data_file_name,names=['time','user_id','item_id','behavior_type','item_category'],header=None,parse_dates=[0])\n",
    "user_behavior_data_one = user_behavior_data[user_behavior_data.user_id == 100198255]\n",
    "user_behavior_data_one.to_csv(\"../DataSet/DevideData/\"+\"oneTest\"+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "user_behavior_data_one= pd.read_csv(\"../DataSet/DevideData/\"+\"oneTest\"+\".csv\",index_col=False,parse_dates=[0])\n",
    "user_behavior_data_one.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = get_feature_u(user_behavior_data_one)\n",
    "res"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "user_behavior_data_temp = user_behavior_data_one.sort_values(by = ['user_id', 'time'])\n",
    "user_behavior_data_temp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res_i = get_feature_i(user_behavior_data_one)\n",
    "res_i[res_i.i_b4_count>0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# res_c = get_feature_c(user_behavior_data_one)\n",
    "res_c[res_c.c_b4_count>0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res_ic = get_feature_ic(user_behavior_data_one)\n",
    "#res_ic[res_ic.item_category==940]\n",
    "res_ic.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res_ui = get_feature_ui(user_behavior_data_one)\n",
    "res_ui[res_ui.ui_b4_count>0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res_uc = get_feature_uc(user_behavior_data_one)\n",
    "res_uc[res_uc.uc_b_count_rank_in_u<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

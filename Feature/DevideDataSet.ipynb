{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def devide_data(user_behavior_data_path, start_day, end_day,validate_or_test_flag=True):\n",
    "    batch = 0\n",
    "    second_end_day = (end_day - datetime.timedelta(days=1))    \n",
    "    start_day_str = str(start_day.date())\n",
    "    end_day_str = str(end_day.date())\n",
    "    second_end_day_str = str(second_end_day.date())\n",
    "    \n",
    "    name = start_day_str + \"to\" + second_end_day_str\n",
    "    #out put file name\n",
    "    part_data_file_name = \"../DataSet/DevideData/\"+\"part_data\"+name+\".csv\"\n",
    "    part_data_label_file_name =  \"../DataSet/DevideData/\"+\"part_data\"+end_day_str+\".csv\"   #end day\n",
    "    part_data_label_filename =  \"../DataSet/DevideData/\"+\"part_data_uicl\"+end_day_str+\".csv\"\n",
    "    print(\"output files name,as follows:\\n\",part_data_file_name,\"\\n\", part_data_label_file_name,\"\\n\", part_data_label_filename)\n",
    "    #\n",
    "    start_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print('get uic label data from %s  to %s start time:'%(start_day_str,end_day_str), start_time)\n",
    "    \n",
    "    dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d %H')\n",
    "    \n",
    "    for df in pd.read_csv(open(user_behavior_data_path, 'r'), \n",
    "                      parse_dates=['time'], \n",
    "                      index_col = ['time'], \n",
    "                      date_parser = dateparse,\n",
    "                      chunksize = 10000000):  # operation on chunk as the data file is too large\n",
    "        try:\n",
    "            part_data = df[start_day_str:second_end_day_str]\n",
    "            part_data_label = df[end_day_str]\n",
    "            #print(\"sangyongjia\",df.head(5))\n",
    "            part_data.to_csv(part_data_file_name,  \n",
    "                             columns=['user_id','item_id','behavior_type','item_category'],\n",
    "                             header=False, mode='a')        \n",
    "            part_data_label.to_csv(part_data_label_file_name,\n",
    "                             columns=['user_id','item_id','behavior_type','item_category'],\n",
    "                             header=False, mode='a')\n",
    "\n",
    "            batch += 1\n",
    "            print('chunk %d done.' %batch) \n",
    "\n",
    "        except StopIteration:\n",
    "            print(\"divide the data set finish.\")\n",
    "            break \n",
    "    #get uic+label data\n",
    "    if(validate_or_test_flag):  #train data\n",
    "        data_file = open(part_data_file_name, 'r')    \n",
    "        try:\n",
    "            part_data = pd.read_csv(data_file, header=None, index_col=False)\n",
    "            #print(\"read nonbbnbe\",part_data)\n",
    "            part_data.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "            #print(\"time\",part_data['time'])\n",
    "        finally:\n",
    "            data_file.close()\n",
    "        part_data_uic = part_data.drop_duplicates(['user_id', 'item_id', 'item_category'])[['user_id', 'item_id', 'item_category']]\n",
    "        #print(part_data)\n",
    "        data_file = open(part_data_label_file_name, 'r')\n",
    "        try:\n",
    "            part_data_label = pd.read_csv(data_file,header=None,index_col=False)    \n",
    "            part_data_label.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "            #print(\"ddsadadsadadslabel3:\",part_data_label,\"\\n\")\n",
    "        finally:\n",
    "            data_file.close()\n",
    "\n",
    "        # uic + label \n",
    "        part_data_uic_label_1 = part_data_label[part_data_label['behavior_type'] == 4][['user_id','item_id','item_category']]\n",
    "        part_data_uic_label_1.drop_duplicates(['user_id','item_id','item_category'], 'last', inplace=True)\n",
    "        part_data_uic_label_1['label'] = 1\n",
    "        part_data_uic_label = pd.merge(part_data_uic, \n",
    "                                       part_data_uic_label_1,\n",
    "                                       on=['user_id','item_id','item_category'], \n",
    "                                       how='left').fillna(0).astype('int')\n",
    "        #print(part_data_uic)\n",
    "        #print(part_data_uic_label_1)\n",
    "        #print(part_data_uic_label)\n",
    "        part_data_uic_label.to_csv(part_data_label_filename, index=False)   \n",
    "        \n",
    "    else:   #predict data\n",
    "        data_file = open(part_data_file_name, 'r')    \n",
    "        try:\n",
    "            part_data = pd.read_csv(data_file, header=None, index_col=False)\n",
    "            part_data.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "        finally:\n",
    "            data_file.close()\n",
    "        part_data_uic = part_data.drop_duplicates(['user_id', 'item_id', 'item_category'])[['user_id', 'item_id', 'item_category']]\n",
    "        part_data_uic.to_csv(part_data_label_filename, index=False)   \n",
    "    end_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print('end time:', end_time)\n",
    "    \"\"\"\n",
    "    start = datetime.datetime(2014,12,15,0,0,0)\n",
    "    end = datetime.datetime(2014,12,18,0,0,0)\n",
    "    devide_data(\"../DataSet/tianchi_fresh_comp_train_user.csv\",start,end)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Unit Test As Follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data = {\"user_id\":[10001082,10001082,10001082,10001082,10001082,10001082,10001083,10001083,10001083,10001083,10001083,10001084,10001084,10001084,10001085],\n",
    "            \"item_id\":[285259775,285259776,285259777,285259778,285259779,285259775,285259875,285259785,285289775,285259975,285259975,285259975,285259975,285259975,285259975],\n",
    "            \"behavior_type\":[1,4,1,2,1,1,1,2,3,1,1,1,3,4,4],\n",
    "            \"user_geohash\":['97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c','97lk14c'],\n",
    "            \"item_category\":[4076,4076,4076,4076,4076,4076,4076,4076,4076,4076,4076,4076,4076,4076,4076],\n",
    "            \"time\":['2014-12-13 01','2014-12-14 18','2014-12-15 08','2014-12-16 10','2014-12-16 18','2014-12-17 18','2014-12-13 01','2014-12-14 18','2014-12-15 08','2014-12-16 10','2014-12-16 18','2014-12-17 18','2014-12-16 10','2014-12-18 18','2014-12-18 18']}\n",
    "test_data = pd.DataFrame(data)\n",
    "test_data.to_csv(\"../DataSet/UnitTestData/DevideDataSetTest.csv\")\n",
    "#各个功能模块正确性验证\n",
    "end = datetime.datetime(2014,12,18,0,0,0)\n",
    "start = end - datetime.timedelta(days=4)    \n",
    "print(start,end)\n",
    "DevideDataSet.devide_data(\"../DataSet/UnitTestData/DevideDataSetTest.csv\", start, end, flag=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = pd.read_csv(\"../DataSet/part_data2014-12-14to2014-12-17.csv\",names=['time','user_id','item_id','behavior_type','item_category'],header=None)\n",
    "b = pd.read_csv(\"../DataSet/part_data2014-12-18.csv\",names=['time','user_id','item_id','behavior_type','item_category'],header=None)\n",
    "c = pd.read_csv(\"../DataSet/part_data_uicl2014-12-18.csv\") "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a.head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b.head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

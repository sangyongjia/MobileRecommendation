能够修改和测试的点
1、将12月11日的数据和12月12日的数据剔除掉
2、将提取特征的天数[4,2,1]进行修改
3、添加新的特征
4、badcase分析？
5、模型参数的调整。
6、周期性和非周期性的数据集
7、离测试日（12月18日 or 19日）约近的数据，其数据权重约高？
8、只以商品子集的数据为训练和预测数据。
9、对非周期的数据，该用更长的时间周期和更短的时间周期
10、
11、如何在保持recall不变的前提下提升precision？？？
=========================================================================
以商品全集上的用户行为数据为基础进行“数据预处理-特征构建-模型调优-模型训练-模型预测”

    周期性的数据集——main
        DataSet-test(validate)数据集：
        以11.29——12.04的数据提取特征，以12.05日的数据给特征数据打上标签
        以11.22——11.27的数据提取特征， 以11.28日的数据给特征数据打上标签

        以12.13——12.18的数据提取特征，用于预测12.19用户是否会购买某些商品。
        以这种方式，以下这篇文章的作者打到了10%以上的f1_score
        https://blog.csdn.net/snoopy_yuan/article/details/75808006
        
    非周期性的数据集——main2
        DataSet-validate数据集：
            12月19日的数据为测试数据集，以12月18日的数据为验证数据集，提取12月17日及以前时间的特征数据。
            141个特征、 
            特征获取天数[4,2,1]、
            模型参数：modle_gbdt = GradientBoostingClassifier(max_depth=12, 
                                                                          min_samples_leaf=10, 
                                                                          learning_rate=0.05, 
                                                                          n_estimators=180,  
                                                                          subsample=0.8, 
                                                                          max_features="sqrt",
                                                                          verbose=True,
                                                                          n_iter_no_change=50,
                                                                          tol=1e-4).fit(df_train_data_X, df_train_data_y)
             可以调用predict函数预测12月18日的购买情况，获取 f1_score，recall_score，precision_score。
             也可以调用predict函数预测12月19日的购买情况，直接提交结果（注：这样得到的线上f1= 0.739, 这样显然是有问题的，
                                                                                                     应该把12月18日的数据也计算在内才合理，但是这样提交后获得的f1= 0.0624）
    非周期性的数据集——main3
        DataSet-test数据集
            以12月19日的数据为测试数据集，提取12月18日及以前时间的特征数据。
            141个特征、 
            特征获取天数[4,2,1]、
            模型参数：modle_gbdt = GradientBoostingClassifier(max_depth=12, 
                                                                          min_samples_leaf=10, 
                                                                          learning_rate=0.05, 
                                                                          n_estimators=180,  
                                                                          subsample=0.8, 
                                                                          max_features="sqrt",
                                                                          verbose=True,
                                                                          n_iter_no_change=50,
                                                                          tol=1e-4).fit(df_train_data_X, df_train_data_y)          
以商品子集上的用户行为数据为基础进行“数据预处理-特征构建-模型调优-模型训练-模型预测”
=======================================================================================
基于规则的方法：
    1、直接提交了12月18号一天的购物车（跟商品子集交）
    2、在1的基础上，剔除掉在30天里从来不买东西的人。
    3、在1的基础上，前一天加入购物车然后当天购买的剔除掉。
    4、在3的基础上，如果发生过购买行为就将其他加入购物车的数据也剔除掉（即将整个人剔除掉）
    5、
    6、
    7、
    8、
    9、
====================
特征融合：




===================
模型融合：
    模型融合的效果取决于
        1、单个模型的性能  （所以在模型融合前，需要努力讲各个模型调到最优）
        2、模型输出的重合度（TopK）
    要对单个模型的输出进行处理后再融合（z-score、ranking score）   ？？？




=====================
新增特征：

=====================
数据清洗：
    1、去掉爬虫用户，即只点击浏览，不收藏，不加购物城，不购买的用户行为数据
    2、去掉异常数据：直接购买了，但是没有点击浏览行为。
    3、


====================
 https://blog.csdn.net/Datuqiqi/article/details/46834579   这个链接中说使用LR得到了一个大于10%的F1 score
 https://www.cnblogs.com/ModifyRong/p/7744987.html    这篇文章讲GBDT的原理介绍的比较明确，但缺点是公式表达形式不一致，有碍精确理解。
 https://blog.csdn.net/Snoopy_Yuan/article/details/72454636  我主要是参考这篇文章写的代码，开始了机器学习做题的路。
 
 
 
 
 ========================
 其他：
 
 1、只有地理位置的数据有缺失，其他数据均无缺失。 2、总数据量是：23291027，缺失数据量为：15911010，7380017条数据是有地理位置信息的，占比为：31.68% 3、应该根据已有的地理位置的记录将缺少的地理位置都补全 存在的情况： 1.完全没有地理位置信息 2.有地理位置信息，但是不一致，存在多个 2.1、多个地理位置信息，明显很近 2.2、多个地理位置信息，差距很大 3.地理位置信息一致 注：2,3描述的都是一个用户的行为记录中存在地理位置信息的情况即可（可能存在很多没有地理位置信息） 4、
#无意间发现一个思路，我可以先预测A会买or不会买，再进一步预测A会买什么!
#现在LR的思路是什么特征的用户会买，但这是通用的思考模式，是否能以推荐的模式来做这个预测，也即评价任意一个用户会不会买某一个商品的标准是个性化的而不是统一的！
#如果我无法找到个性化的预测的方式，那可以“排行榜--> 分类排行榜 --> 分人群个性化 --> 针对个人的个性化”的思路来，首先可以将人分为：
#果断型的、正常型、犹豫型的。根据直观的感觉，一般男性是果断型的，女性为犹豫比较型的。根据这两个维度可以求和交集，共分为6类！
#注：我确实没有男女的数据，但将用户行为分为两类，是不需要男女信息的。
#一个是点击率预估，一个是聚类。
 
 
 
 
 
 
 
 
 
 
 
 
    
                                                      